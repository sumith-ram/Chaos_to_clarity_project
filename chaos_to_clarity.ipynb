{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "787e9b91-bc4e-45d0-95cb-34abe1a1265c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messy data saved to E:/da_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def generate_chaotic_data(num_records=100):\n",
    "    # Some sample names with mixed case and possible None values\n",
    "    names = [\"Alice\", \"bob\", \"CHARLIE\", \"David\", None, \"Eva\", \"frank\", \"Gina\", \"henry\", \"Isaac\"]\n",
    "    ages = [25, \"thirty\", 35, None, 45, 50, \"forty\", 29, None, 40]\n",
    "    heights = [165, 170, 180, 175, None, 160, 172, 168, 174, \"one seventy\"]\n",
    "    weights = [55, 65, None, 70, 68, 60, \"sixty five\", 58, 62, 66]\n",
    "    emails = [\n",
    "        \"alice@example.com\", \"bob[at]email.com\", \"charlie.email.com\", \"david@mail.com\",\n",
    "        \"eva@example\", None, \"frank@mail.com\", \"gina@email.com\", \"henry@mail\", \"isaac@mail.com\"\n",
    "    ]\n",
    "    join_dates = [\n",
    "        \"2023-01-10\", \"2023/02/20\", \"March 15, 2023\", \"2023-04-01\", None, \"2023-06-30\",\n",
    "        \"2023-07-15\", \"2023-08-20\", \"2023-09-25\", \"2023-10-10\"\n",
    "    ]\n",
    "\n",
    "    data = {\n",
    "        \"Name\": [],\n",
    "        \"Age\": [],\n",
    "        \"Height_cm\": [],\n",
    "        \"Weight_kg\": [],\n",
    "        \"Email\": [],\n",
    "        \"JoinDate\": []\n",
    "    }\n",
    "\n",
    "    for _ in range(num_records):\n",
    "        i = random.randint(0, 9)\n",
    "        # Add some randomness/noise\n",
    "        name = names[i]\n",
    "        # Add noise to name sometimes\n",
    "        if random.random() < 0.1:\n",
    "            name = name.lower() if name else name\n",
    "        age = ages[i]\n",
    "        height = heights[i]\n",
    "        weight = weights[i]\n",
    "        email = emails[i]\n",
    "        join_date = join_dates[i]\n",
    "\n",
    "        # Occasionally insert extra noise\n",
    "        if random.random() < 0.05:\n",
    "            age = \"unknown\"\n",
    "        if random.random() < 0.05:\n",
    "            weight = \"N/A\"\n",
    "        if random.random() < 0.05:\n",
    "            join_date = \"unknown\"\n",
    "\n",
    "        data[\"Name\"].append(name)\n",
    "        data[\"Age\"].append(age)\n",
    "        data[\"Height_cm\"].append(height)\n",
    "        data[\"Weight_kg\"].append(weight)\n",
    "        data[\"Email\"].append(email)\n",
    "        data[\"JoinDate\"].append(join_date)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def save_messy_data(filepath=\"E:/da_dataset.csv\"):\n",
    "    df = generate_chaotic_data(100)\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f\"Messy data saved to {filepath}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    save_messy_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72246f6-4ec2-41a3-a503-3ea0c01f7589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading messy data from E:/da_dataset.csv ...\n",
      "Removed 0 outlier rows.\n",
      "\n",
      "=== Chaos to Clarity Cleaning Report ===\n",
      "Original rows: 64\n",
      "Cleaned rows: 64\n",
      "\n",
      "Column Data Types:\n",
      "Name                 object\n",
      "Age                 float64\n",
      "Height_cm           float64\n",
      "Weight_kg           float64\n",
      "Email                object\n",
      "JoinDate     datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "Sample cleaned data:\n",
      "    Name   Age  Height_cm  Weight_kg              Email   JoinDate\n",
      "0    Bob  35.0      170.0       65.0      bob@email.com 2023-02-20\n",
      "1  Alice  25.0      165.0       55.0  alice@example.com 2023-02-20\n",
      "2  Isaac  35.0      170.0       66.0     isaac@mail.com 2023-02-20\n",
      "4  Frank  40.0      172.0       65.0     frank@mail.com 2023-02-20\n",
      "7  Isaac  40.0      170.0       66.0     isaac@mail.com 2023-02-20\n",
      "\n",
      "Unique Names:\n",
      "['Alice', 'Bob', 'David', 'Frank', 'Gina', 'Isaac']\n",
      "\n",
      "Most common email domains:\n",
      "[('mail.com', 29), ('email.com', 21), ('example.com', 14)]\n",
      "\n",
      "Cleaned data saved as E:/da_dataset_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "\n",
    "# Step 1: Normalize Text (names, emails)\n",
    "def normalize_text(df):\n",
    "    df['Name'] = df['Name'].astype(str).str.strip().str.title()\n",
    "\n",
    "    def clean_email(email):\n",
    "        if pd.isna(email) or email.lower() in ['none', 'nan', '']:\n",
    "            return np.nan\n",
    "        email = email.replace(\"[at]\", \"@\").strip()\n",
    "        pattern = r\"[^@]+@[^@]+\\.[^@]+\"\n",
    "        if re.match(pattern, email):\n",
    "            return email.lower()\n",
    "        return np.nan\n",
    "    df['Email'] = df['Email'].apply(clean_email)\n",
    "    return df\n",
    "\n",
    "# Step 2: Fix numeric columns (convert text numbers to numerics)\n",
    "def fix_numeric_columns(df):\n",
    "    text_to_num = {\n",
    "        \"thirty\": 30, \"forty\": 40, \"sixty five\": 65, \"one seventy\": 170,\n",
    "        \"unknown\": np.nan, \"n/a\": np.nan\n",
    "    }\n",
    "    for col in ['Age', 'Height_cm', 'Weight_kg']:\n",
    "        def convert_value(val):\n",
    "            if pd.isna(val):\n",
    "                return np.nan\n",
    "            if isinstance(val, (int, float)):\n",
    "                return val\n",
    "            val = str(val).lower()\n",
    "            if val in text_to_num:\n",
    "                return text_to_num[val]\n",
    "            try:\n",
    "                return float(val)\n",
    "            except:\n",
    "                return np.nan\n",
    "        df[col] = df[col].apply(convert_value)\n",
    "    return df\n",
    "\n",
    "# Step 3: Impute missing values intelligently\n",
    "def impute_missing(df):\n",
    "    numeric_cols = ['Age', 'Height_cm', 'Weight_kg']\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
    "\n",
    "    df.dropna(subset=['Name', 'Email'], inplace=True)\n",
    "\n",
    "    df['JoinDate'] = pd.to_datetime(df['JoinDate'], errors='coerce')\n",
    "    earliest_date = df['JoinDate'].min()\n",
    "    df['JoinDate'] = df['JoinDate'].fillna(earliest_date)\n",
    "    return df\n",
    "\n",
    "# Step 4: Remove outliers using z-score\n",
    "def remove_outliers(df):\n",
    "    numeric_cols = ['Age', 'Height_cm', 'Weight_kg']\n",
    "    scaler = StandardScaler()\n",
    "    scaled = scaler.fit_transform(df[numeric_cols])\n",
    "    z_scores = np.abs(scaled)\n",
    "    filter_mask = (z_scores < 3).all(axis=1)\n",
    "    removed_count = len(df) - np.sum(filter_mask)\n",
    "    df_clean = df[filter_mask].copy()\n",
    "    print(f\"Removed {removed_count} outlier rows.\")\n",
    "    return df_clean\n",
    "\n",
    "# Step 5: Summary report\n",
    "def summary_report(df_raw, df_clean):\n",
    "    print(\"\\n=== Chaos to Clarity Cleaning Report ===\")\n",
    "    print(f\"Original rows: {len(df_raw)}\")\n",
    "    print(f\"Cleaned rows: {len(df_clean)}\")\n",
    "    print(\"\\nColumn Data Types:\")\n",
    "    print(df_clean.dtypes)\n",
    "    print(\"\\nSample cleaned data:\")\n",
    "    print(df_clean.head())\n",
    "    print(\"\\nUnique Names:\")\n",
    "    print(sorted(df_clean['Name'].unique()))\n",
    "    print(\"\\nMost common email domains:\")\n",
    "    domains = df_clean['Email'].str.split('@').str[1]\n",
    "    print(Counter(domains).most_common(5))\n",
    "\n",
    "def main():\n",
    "    filepath = \"E:/da_dataset.csv\"\n",
    "    print(f\"Loading messy data from {filepath} ...\")\n",
    "    df_raw = pd.read_csv(filepath)\n",
    "\n",
    "    df_norm = normalize_text(df_raw)\n",
    "    df_num_fixed = fix_numeric_columns(df_norm)\n",
    "    df_imputed = impute_missing(df_num_fixed)\n",
    "    df_clean = remove_outliers(df_imputed)\n",
    "\n",
    "    summary_report(df_raw, df_clean)\n",
    "\n",
    "    output_path = \"E:/da_dataset_cleaned.csv\"\n",
    "    df_clean.to_csv(output_path, index=False)\n",
    "    print(f\"\\nCleaned data saved as {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6fa635-efb7-4b3f-854b-cffb04df19b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
